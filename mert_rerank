#!/usr/bin/env python
import optparse
import sys
import bleu

def dot_prod(a, b):
    assert (len(a) == len(b))
    product = 0.0
    for i in xrange(len(a)):
        product += (a[i] * b[i])

    return product


def scalar_mult(s, a):
    assert (len(a) == len(b))
    for i in xrange(len(a)):
        a[i] = a[i] * s

    return a


def vector_add(a, b):
    assert (len(a) == len(b))
    for i in xrange(len(a)):
        a[i] = a[i] + b[i]

    return a

def vector_sub(a, b):
    assert (len(a) == len(b))
    for i in xrange(len(a)):
        a[i] = a[i] - b[i]

    return a

class MERT:
    def __init__(self):
        self.initiated = True

    # Based on Powell's Quadratically Convergent Method on page 511 of
    # Numerical Recipes 3rd Edition: The Art of Scientific Computing
    def run_mert_powell(self, ref, data, w=(1.0, 1.0, 1.0), directions=[(1.0,0.0,0.0), (0.0,1.0,0.0), (0.0,0.0,1.0)]):
        p = {0: w}
        dim = len(directions)

        prev = float('inf')
        while (True):
            for i, d in enumerate(directions):
                p[i+1] = line_search(ref, data, p[i] , d)

            for j in xrange(dim - 1)):
                directions[j] = directions[j+1]

            directions[dim-1] = p[dim] - p[0]
            
            p[0] = line_search(ref, data, p[dim], directions[dim-1]) 
            new_score = self.evaluate(ref, data, p[0])
            if new_score >= prev:
                break
            prev = new_score

        return p[0]

    def line_search(self, ref, data, w, d):
        assert (len(w) == len(d))
        epsilon = 0.0 # ???TODO
        m = {}
        b = {}
        intercepts = []
        for candidates in data:
            # Identifying the points e as their num, hopefully more efficient
            for (e, hypo, features) in candidates:
                m[e] = dot_prod(features, d)
                b[e] = dot_prod(features, w)

            best_n = None
            max_n_value = 0.0
            for (e, hypo, features) in candidates:
                if m[e] > max_n_value:
                    best_n = e
                    max_n_value = m[e]
                elif m[e] == max_n_value:
                    # b[e] breaks ties
                    if b[e] > b[best_n]:
                        best_n = e
                        max_n_value = m[e]
            assert (best_n is not None)

            while (True):
                best_np1 = None
                min_np1_value = float("inf")
                # Looking for argmin this time
                for (e, hypo, features) in candidates:
                    i = (b[best_n] - b[e]) / (m[e] - m[best_n])
                    val = max(0.0, i)
                    if val < min_np1_value:
                        best_np1 = e
                        min_np1_value = val
                assert (best_np1 is not None)

                int_cand = (b[best_n] - b[best_np1]) / (m[best_np1] - m[best_n])
                intercept = max(0.0, intercept)
                if intercept > 0.0:
                    intercepts.append(intercept)
                else:
                    break

        intercepts.append(max(intercepts) + 2(epsilon))
        i_best = None
        min_i_score = float("inf")
        for intercept in intercepts:
            weights = vector_add(w, scalar_mult(i, d))
            val = 1 - self.evalute(ref, data, weights, d)
            if val < min_i_score:
                i_best = intercept
                min_i_score = val

        assert (i_best is not None)

        return vector_add(w, scalar_mult(i_best, d))

    def evaluate(self, ref, data, w):
        stats = [0 for i in xrange(10)]
        for j, candidates in enumerate(data):
            best = None
            for (e, hypo, features) in candidates:
                score = 0.0
                for k in xrange(len(features)):
                    score += w[k] * features[k]
                if score > best_score:
                    (best_score, best) = (score, hyp)

            assert (best is not None)
            
            stats = [sum(scores) for scores in zip(stats, bleu.bleu_stats(ref[j],best))]
        return bleu.bleu(stats)


if __name__ == '__main__':
    optparser = optparse.OptionParser()
    optparser.add_option("-r", "--reference", dest="reference", default="data/dev.ref", help="Target language reference sentences")
    optparser.add_option("-k", "--kbest-list", dest="input", default="data/dev+test.100best", help="100-best translation lists")
    optparser.add_option("-l", "--lm", dest="lm", default=-1.0, type="float", help="Language model weight")
    optparser.add_option("-t", "--tm1", dest="tm1", default=-0.5, type="float", help="Translation model p(e|f) weight")
    optparser.add_option("-s", "--tm2", dest="tm2", default=-0.5, type="float", help="Lexical translation model p_lex(f|e) weight")
    (opts, _) = optparser.parse_args()
    init_weights = {'p(e)'       : float(opts.lm) ,
                    'p(e|f)'     : float(opts.tm1),
                    'p_lex(f|e)' : float(opts.tm2)}

    ref = [line.strip().split() for line in open(opts.reference)]
    all_hyps = [pair.split(' ||| ') for pair in open(opts.input)]
    num_sents = len(all_hyps) / 100
    mert = MERT()   # M.E.R.T. engine
    
    data = []
    for s in xrange(0, num_sents):
        hyps_for_one_sent = all_hyps[s * 100:s * 100 + 100]
        candidates = []
        for (num, hyp, feats) in hyps_for_one_sent:
            features = []
            for feat in feats.split(' '):
                (k, v) = feat.split('=')
                features.append(v)
            candidates.append((num, hyp, tuple(features)))
        data.append(candidates)

    w = (float(opts.lm), float(opts.tm1), float(opts.tm2))
    best_w = mert.run_mert_powell(ref, data, w)

    for candidates in data:
        for (e, hypo, features) in candidates:
            score = 0.0
            for k in xrange(len(features)):
                score += best_w[k] * features[k]
            if score > best_score:
                (best_score, best) = (score, hyp)

            try: 
                sys.stdout.write("%s\n" % best)
            except (Exception):
                sys.exit(1)

